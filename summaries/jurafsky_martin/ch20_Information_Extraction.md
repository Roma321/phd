В данной главе приводится обзор задачи **выделения информации (Information extraction)**. 

* **Выделение отношений (relation extraction)** — выделение и классификация семантических связей между 2 сущностями по типу часть-целое, гипоним-гипероним или пространственные отношения. Используется для наполнения реляционныз БД или баз знаний.
* **Выделение событий (event extraction)** — поиск событий, действий, в которых участвуют сущности. Задача так же включает определение времеенных границ события. **Нормализацией во времени** события называют маппинг любых временных выражений, в т. ч. относительных *(на следующей неделе)* в абсолютные (календарные).
* **Template filling (заполнение шаблонов)** — выделение характеристик типовых событий по заранее заданному списку признаков.

## Выделение отношений
Отношения обычно описывается с помощью **RDF-triple (тройки subject-predicate-object)**. Существует проект **DBPedia**, хранящий миллиарды таких связей, собранный и самообновляющийся на материалах Википедии. **Freebase** — ещё один подобный проект. Проект **WordNet** содержит исключительно связи гипоним-гипероним. Датасет **TACRED** представляет собой 106,264 тройки 41 типа, размеченных в предложениях

**Алгоритмы выделения отношений** подразделить на 4 группы

1. Распознание на основе паттернов, заданных вручну.
2. Обучение с учителем
3. Частично контролируемое обучение
4. Обучение без учителя 

### Распознание паттернов
Также иногда носит название "паттерны Хёрста" — по фамилии изобретателя в 1992 году. Это буквально вручную прописанные правила формата "если в приложении можно выделить паттерн $N_0$, such as $N_1$, то $N_1$ и $N_0$ связан отношением "Гипоним-гипероним". Из преимуществ этого подхода можно выделить высокую точность и возможность адаптации к довольно специфическим предметным областям. Из недостатков стоит отметить низкую полноту, высокий объём работы для ручного написания всех возможных паттернов, а также слабую работу со флективными языками.

### Обучение с учителем
Имеется классическое машинное обучение с учителем -- с полноценным размеченным датасетом, тестовой и валидационной выборкой.
Задача может, например, быть поставлена так:

1. Выделить именованные сущности из текста
2. Подать на вход любому классификатору (на наличие отношения) все пары именованных сущностей, с учётом контекста либо без него

Классификаторы классического типа (Random Forest, линейная регрессия, перцептроны) могут принимать на вход признаки

1. **Векторное представление** — эмбеддинги BERT, tf-idf, Bag of words, "Bag of bigrams"
2.  **Признаки именованных сущностей** — тип (компания, человек, река), уровень ({NAME, NOMINAL, PRONOUN} ~ {название, тип, местоимение}, н-р, {Иван, человек, он})
3. **Синтаксические признаки** — количество других слов между именованным сущностями, синтаксические и грамматические признаки, синтаксический путь между 2 именованными сущностями

Основным недостатком такого метода является необходимость наличия размеченного датасета, что требует большого объёма усилий

### Частично контролируемое обучение: бутстрэппинг

В отличие от обучения с учителем, этот метод не требует размеченного датасета. Для его работы достаточно нескольких **исходных паттернов (seed patterns)** или **исходных кортежей (seed tuples)**. Этого достаточно, чтобы запустить процесс **бутстрэппинга** классификатора. Например:

1. Известно, что Ryanair и Шарлеруа связаны отношением "Авиакопания-хаб".
2. Запускается поиск всех предложений, имеющих слова Ryanair, Шарлеруа, хаб.
3. Затем, из этих предложений выделяется контекст между использованными словами и, возможно, по одному слову вокруг них
4. С использованием контекста, признаков именованных сущностей и прочих черт выделяются паттерны, образующие связь "Авиакомпания-хаб"

Подобные системы могут также выдавать паттернам **меру уверенности (confidence values)**. Она используется для избежания **семантического смещения (semantic drift)** — ситуации, когда ошибочные паттерны приводят к выделению ошибочных кортежей, которые приводят к выделению ошибчоных паттернов и т д.

Уверенность в паттерне можно оценить по следующей формуле:
$$
Conf_{RlogF}(p) = \frac{|hits(p)|}{|finds(p)|}\log(|finds(p)|)
$$
где:
* **hits(p)** — количество кортежей, которые найдены данным паттерном и помечены как seed tuples на данной итерации алгоритма
* **finds(p)** — общее количество кортежей, которые найдены данным паттерном.

Уверенность в кортеже тоже можно рассчитать. Предположим, у нас есть кортеж t и набор поддерживающих его паттернов P, для каждого из которых уже тоже рассчитана мера уверенность.

Тогда уверенность в кортеже можно рассчитать с помощью техники **noisy-or** — по сути просто перемножить вероятности, что все поддерживающие паттерны ошиблись одновременно

$$
Conf(t) = 1 - \prod_{p \in P'} (1 - Conf(p))
$$

### Частично контролируемое обучение: дистанционное обучение


Его идея заключается в том, что вместо набора из нескольких вручную заданных паттернов, мы берём данные из существующего крупного датасета и на их основе обучаем классификатор

1. Берём крупный существующий датасет (н-р, DBPedia)
2. Достаём из него все кортежи по некоторому отшению
3. Ищем все предложения, содержащих обе именованные сущности из кортежа
4. Все они признаются положительными примерами для данного типа отношений
5. На их основании можно выделить новые паттерны или же обучить классификатор, отвественный за выделение данного типа отношений. В связи с высоким объёмом обучающей выборки, можно получить довольно сложно устроенные паттерны.

Основным минусом данного подхода является высокая зашумлённость, т. к. на самом деле далеко не все найденные предложения явялются положительными примерами. То есть, метод имеет низкую точность и актуальные исследования нацелены на то, чтобы эту точность повысить. Ещё к недостаткам можно отнести потребность в большом датасете.

### Обучение без учителя
Целью алгоритмов, использующих обучение без учителя обычно является извлечение информации в условиях, где мы не имеем ни разметки, ни заранее известного списка возможных отношений (например, в открытом Интернете). Данная задача также иногда называется задачей **извлечения информации (Information Extraction, IE)**

Одна из систем, реализующих этот подход — **ReVerb (2011)**. Её алгоритм по извлечению информации из предложения:

1. В предложении определяет часть речи и границы сущностей (entities chunking)
2. Для каждого глагола с учётом набора ограничений берётся наибольшая последовательность **w** зависящих от него слов
3. Для каждого выражения с шага (2) найти ближайшее существительное слева и справа (игнорируя притяжательные местоимения, вопросительные слова, слово there), формируя таким образом тройку **(x, w, y)**
4. С помощью классификатора выяснить, содержит ли тройка **(x, w, y)** какое-нибудь отношение.

В список ограничений входит, например, правило, что глагол (или глагольные выражения вроде *have hub in*) является главным словом. Слишком длинные и редко встечающиеся выражения (потенциальные отношения) также отбрасываются. В оригинальное работе обрабатываются 500млн предложений, и извлечённые отношения добавляются в общий словарь, если встречаются хотя бы с 20 разными аргументами. В ходе работы извлечено 1.7 млн отношений.

Затем, каждое отношение подаётся на вход обученному классификатору, коорый выдаёт каждому отношению меру уверенности.

### Оценка алгоритмов выделения отношений

* Для методов обучения с учителем используется классические точность, полнота, $F$-мера.
* Для методов частично контролируемого и дистанционного обучения, обучения без учителя эти метрики не подходят, так как алгоритмы работают на неразмеченных и крайне больших объёмах данных данных. Предлагется метод оценки точности по части выборки следующим образом: 
$$
\hat{P} = \frac{\text{Количество найденных корректных кортежей}}{\text{Общее количество найденных кортежей}}
$$ 

## Выделение событий
Под задачей **выделения событий (event extraction)** подразумевается выделение событий из текста и размещение их на временной шкале.

В английском языке события обычно выражаются глаголами, но это не всегда так. Например, в событии *Increase took effect*  произошедшее событие — это повышение, а глагол, напротив, событием не является. Также обычно не являются событием **слабые глаголы (light verbs)** вроде *make, take, have*, они являются "синтаксической поддержкой" для событий, выраженных существительными (*took a flight*)

Системы извлечения событий могут иметь разные дополнительные цели, например, их классификацию (скажем, действия/состояния/сообщения), законченность и пр.
В качестве основного подхода для задачи извлечения событий используется обучение с учителем.

### Методы представления основных харакеристик событий
#### Представление времени
Основным способом представления относительного времени действия 2 интервальных событий является интервальная алгебра, представленная Алленом в 1984. Одномоментные события она не рассматривает. Ниже изображены все 13 **отношений Аллена**

![Виды временнных отношений по Аллену](images/allen_intervals.png)

Для событий, выраженных моментами, тоже не всё так просто. 
Авторы отмечают, что форма глагола не всегда связана с истинным временем события. Так, в фразе *Ok, we fly from San Francisco to Boston at 10* будущее время выражено глаголом настоящего.

Ещё один пример, который они отмечают

*Flight 1902 arrived late.*  
*Flight 1902 had arrived late*

Не все события, произошедшие в прошлом, равнозначны по своему временному расположению. Так, во втором примере подразумевается, что какое-то событие уже произошло к моменту описываемого. Для описания этого феномена Райхенбах в 1947 ввёл понятие **референсной точки (refernce point)**, то есть момента, о котором говорится, который используется как основной на момент опсиываемого события. С помощью этой схемы хорошо описываются основные времена английского языка.

![Референсные точки по Райхенбаху](images/reichenbach_points.png)

$E$ — время события  
$R$ — референсная точка  
$U$ — время высказывания

В естественных языках время может описываться не только с помощью грамматической категории времени, но и с помощью временных выражений (*утром*, *после этого*) или метафорически, например, с помощью пространственных выражений (*около того*, *где-то в понедельник*)

#### Представление аспекта
С помощью аспекта события описываются по их внутренней временной струкутуре или временному контуру, то есть их завершённости, продолженности, регулярности. Выделяют категории:

1. **Состояния (States)** — неизменные продолжающиеся события (*я люблю поезда*)
2. **События (Events)** — всё, что не является состоянием
    1. **Деятельность (Activity)** — продолжающиеся события без чётко обозначенной точки завершения (*Я живу в Москве*, *Она ехала на Мазде*)
    2. **Выполнения (Accomplishment)** — события, занявшие определённое время и имеющие чёткую точку завршения. Также  называются **целенаправленными (telic)** событиями. (*Он забронировал столик*)
    3. **Достижения (Achievement)** — события, имеющие чёткую точку завершения, но не имеющие продолжительности. (*Она нашла свой выход на посадку*)

**Stative:** I know my departure gate.  
**Activity:** John is flying.  
**Accomplishment:** Sally booked her flight.  
**Achievement:** She found her gate.

### Алгоритмы выделения времени 
Основным датасетом является **TimeBank**. Он содержит английские тексты с разметкой 3 типов объектов — EVENT (события и состояни), TIME (выражения, описывающие время), LINK (связи событий с временными выражениями). LINK разделяются на TLINK (по Аллену), ALINK (аспект), SLINK.

##### Пример из датасета TimeBank
```xml
<TIMEX3 tid="t57" type="DATE" value="1989-10-26" functionInDocument="CREATION_TIME">
  10/26/89
</TIMEX3>
Delta Air Lines earnings
<EVENT eid="e1" class="OCCURRENCE">soared</EVENT>
33% to a record in
<TIMEX3 tid="t58" type="DATE" value="1989-Q1" anchorTimeID="t57">
  the fiscal first quarter
</TIMEX3>,
<EVENT eid="e3" class="OCCURRENCE">bucking</EVENT>
the industry trend toward
<EVENT eid="e4" class="OCCURRENCE">declining</EVENT>
profits.

```
* $\text{Soaring}_{e1}$ is included in $\text{the fiscal first quarter}_{t58}$
* $\text{Soaring}_{e1}$ is before $\text{1989-10-26}_{t57}$
* $\text{Soaring}_{e1}$ is simultaneous with $\text{the bucking}_{e3}$
* $\text{Declining}_{e4}$ includes $\text{soaring}_{e1}$

Основные шаги при выделении времени:

1. Выделение **временных выражений**
2. **Нормализация** выражений через приведение их в стандартный формат
3. **Соотнесение** их с событиями, создания временного графа или временной линии

#### Выделение временных отношений

1. **Абсолютные** — могут быть напрямую соотнесены с датой или временем
2. **Относительные** — указывают на время, относительно некоторого события или референсной точки. (*a week from last tuesday*)
3. **Длительность** — промежутки времени

| **Absolute**            | **Relative**             | **Durations**           |
| ----------------------- | ------------------------ | ----------------------- |
| April 24, 1916          | yesterday                | four hours              |
| The summer of ’77       | next semester            | three weeks             |
| 10:15 AM                | two weeks from yesterday | six days                |
| The 3rd quarter of 2006 | last quarter             | the last three quarters |


Временные выражения часто имеют **лексические триггеры** в качестве своих главных слов, что делает их выделение проще

| **Category** | **Examples**                                                |
| ------------ | ----------------------------------------------------------- |
| Noun         | *morning, noon, night, winter, dusk, dawn*                  |
| Proper Noun  | *January, Monday, Ides, Easter, Rosh Hashana, Ramadan, Tet* |
| Adjective    | *recent, past, annual, former*                              |
| Adverb       | *hourly, daily, monthly, yearly*                            |

Для выделения выражений можно использовать подходы, основанные на правилах. Например, наборы регулярных выражений на основе частей речи или определённых лексических единиц.
Ещё один подход — машинное обучение. Каждому слову должна быть выдана метка на основе стандарной **IOB-схемы** (inside, outside, beginning). 
```
A fare increase initiated last week by UAL Corp’s...  
 O   O     O         O      B    I   O   O    O    
```

#### Нормализация временных отношений
**Временная нормализация** — это задача представления временных выражений как точки во времени или как длительности. 
Нормализованное время обычно представляется в формате ISO

```xml
<TIMEX3 id="t1" type="DATE" value="2007-07-02" functionInDocument="CREATION_TIME">
  July 2, 2007
</TIMEX3>
A fare increase initiated
<TIMEX3 id="t2" type="DATE" value="2007-W26" anchorTimeID="t1">
  last week
</TIMEX3>
by United Airlines was matched by competitors over
<TIMEX3 id="t3" type="DURATION" value="P1WE" anchorTimeID="t1">
  the weekend
</TIMEX3>,
marking the second successful fare increase in
<TIMEX3 id="t4" type="DURATION" value="P2W" anchorTimeID="t1">
  two weeks
</TIMEX3>.
```

| Unit                     | Pattern             | Sample Value        |
|--------------------------|---------------------|---------------------|
| Fully specified dates    | YYYY-MM-DD          | 1991-09-28          |
| Weeks                    | YYYY-Wnn            | 2007-W27            |
| Weekends                 | PnWE                | P1WE                |
| 24-hour clock times      | HH:MM:SS            | 11:13:45            |
| Dates and times          | YYYY-MM-DDTHH:MM:SS | 1991-09-28T11:00:00 |
| Financial quarters       | Qn                  | 1999-Q3             |

(**P** в формате ISO означает period, продолжительность)

Современные подходы для нормализации времени в основном rule-based. Например, для 2 распознанных паттернов временных выражений можно определить операцию DURATION, которая определит длительность между ними.

Задача нормализации времени явялется довольно сложной, поскольку в документах довольно редко встречаются чёткие указания на дату и время. Чаще они ссылаются, например, на время написания документа — эту дату называют **temporcal anchor, временным якорем**.  На основе этого якоря можно рассчитывать даты, упоминающиеся со словами *yesterday, tomorrow, next week*. Стоит отметить, что этого тоже недостаточно. Рассмотрим примеры

* *Random security checks that began yesterday at Sky Harbor will continue
at least through **the weekend**.*
* *A fare increase initiated by United Airlines was matched by competitors over   **the weekend** marking the second successful fare increase in   two weeks*

В первом случае **the weekend** ссылается на предстоящий уикэнд, а во втором — на прошедший.

Это может зависеть не только от временных форм глагола. Так, выражение *в следующую пятницу*, сказанное в субботу, будет скорее всего иметь в виду ближайшую пятницу, а выражение *в следующую пятницу*, сказанное в четверг, скорее всего будет подразумевать уже не ближайшую пятницу, а ту, которая будет за ней.

Такие неоднозначности обычно разрешаются разнообразными эвристиками, специфичными для языка и предметной области.

#### Упорядочивание событий во времени.

Целью темпорального анализа является соотнесение времени описанных в тексте событий с линией времени. Более простая задача — задание отношение частичного порядка на множестве описанных в тексте событий тоже является довольно полезной. В этой постановке она может быть рассмотрена как задача **Relation extraction**.

В любой постановке задача все ещё требует извлечения событий из текста, а также извлечения временных выражений и нормализации. Построению ясной временной линии может мешать тот факт, что значительная часть временных выражений задаётся не относительно других таких же временных выражений, а относительно событий (н-р, *One week after the storm, JetBlue issued its customer bill of rights.*)

После извлечения событий и времён требуется установить между ними связи (как в датасете **TimeBank**).  Это можно сделать с помощью классификаторов разнообразных архитектур, подавая им на вход каждую пару "время-событие".

Системы, выполняющие все четыре задачи (извлечение, создание и нормализацию временных выражений, извлечение событий и связывание времени и событий), включают **TARSQI** (Verhagen и др., 2005), **CLEARTK** (Bethard, 2013), **CAEVO** (Chambers и др., 2014) и **CATENA** (Mirza и Tonelli, 2016).

## Заполнение шаблонов (template filling)

**Template Filling** — это задача извлечения структурированной информации из текста на основе заранее заданных **шаблонов (templates)**, которые представляют типичные сценарии событий — так называемые **скрипты (scripts)**. Скрипт описывает типичную последовательность под-событий, участников и их ролей. Система должна распознать, что текст описывает определённый скрипт, и заполнить соответствующие слоты шаблона конкретными данными, извлечёнными из текста или выведенными по смыслу.

Например, в тексте

```
Citing high fuel prices, United Airlines said Friday it has increased fares
by $6 per round trip on flights to some cities also served by lowercost carriers. American Airlines, a unit of AMR Corp., immediately
matched the move, spokesman Tim Wagner said. United, a unit of UAL
Corp., said the increase took effect Thursday and applies to most routes
where it competes against discount carriers, such as Chicago to Dallas
and Denver to San Francisco.
```

могут быть заполнены следующие шаблоны:

| Slot               | Value              |
|--------------------|--------------------|
| **Lead Airline**   | UNITED AIRLINES    |
| **Amount**         | $6                 |
| **Effective Date** | 2006-10-26         |
| **Follower**       | AMERICAN AIRLINES  |


### Методы машинного обучения

Подход машинного обучения к **Template Filling** основан на обучении моделей по размеченным данным, где тексты содержат заранее определённые шаблоны и заполнители (slot fillers). Задача состоит в том, чтобы для каждого события создать шаблон и заполнить его нужными элементами текста.

Процесс обычно делится на две части:

1. **Template recognition (распознавание шаблона / события)** — классификация текста, определяющая, описывает ли предложение нужный тип шаблона. Используются стандартные признаки: токены, embeddings, части речи, синтаксические фрагменты и именованные сущности.
2. **Role-filler extraction (извлечение заполнителей слотов)** — отдельный классификатор для каждого слота (например, *LEAD-AIRLINE*, *AMOUNT* и т.д.), который ищет подходящие выражения. Это может быть и бинарный классификатор, применяемый к каждому слову с учётом контекста, и модель, применяемая к последовательности и возвращающая указатель на филлер.

Иногда одно и то же событие может быть выражено несколькими вариантами (например, *United* и *United Airlines*), что требует разрешения кореференции. Подход оценивается на размеченных корпусах (например, объявления о работе, научные конференции, рестораны, биологические тексты).

Открытая исследовательская проблема — извлечение шаблонов без заранее определённых данных, то есть автоматическое порождение самих шаблонов из связанных событий.

### Ранние подходы на основе конечных автоматов
Эти подходы использовали **конечные автоматы с выводом (finite state transducers)**. Первые четыре стадии выполняли разбиение текста — токенизацию, выделение фраз и синтаксическую сегментацию. На пятом этапе FST-распознаватели, построенные на регулярных выражениях, определяли сущности и события и заполняли ими слоты шаблонов.

## Итог
В этой главе рассматривались методы извлечения ограниченных форм семантического содержания из текстов.

* **Отношения между сущностями** могут извлекаться с помощью шаблонных (pattern-based) подходов, методов **обучения с учителем** (если есть размеченные данные), **частчино контролируемых** методов (при наличии небольшого числа исходных пар или шаблонов), **дистанционного обучения** (если есть база данных отношений), а также **неконтролируемых** методов.
* **Работа со временем** включает обнаружение и нормализацию временных выражений, что помогает рассуждать о временной структуре текста.
* **События** можно упорядочивать во времени с помощью последовательных моделей и классификаторов, обученных на данных, размеченных по времени и событиям (например, корпус **TimeBank**).
* **Приложения на основе шаблонов (template filling)** позволяют распознавать типичные ситуации в текстах и соотносить элементы текста с ролями, представленными в виде фиксированных наборов слотов.

## Мои выводы
Описанные в этой главе проблемы содержат больше открытых задач. К ним относится совершенствование методов обучения без учителя и методов, работающих без предопределённого набора шаблонов/отношений. 

Также глава описывает актуальные результаты для английского языка и строго для новостной публицистики, что предполагает возможность исследований по применению этих методов к другим языкам.