В данной главе приводится обзор задачи **выделения информации (Information extraction)**. 

* **Выделение отношений (relation extraction)** — выделение и классификация семантических связей между 2 сущностями по типу часть-целое, гипоним-гипероним или пространственные отношения. Используется для наполнения реляционныз БД или баз знаний.
* **Выделение событий (event extraction)** — поиск событий, действий, в которых участвуют сущности. Задача так же включает определение времеенных границ события. **Нормализацией во времени** события называют маппинг любых временных выражений, в т. ч. относительных *(на следующей неделе)* в абсолютные (календарные).
* **Template filling (заполнение шаблонов)** — выделение характеристик типовых событий по заранее заданному списку признаков.

### Выделение отношений
Отношения обычно описывается с помощью **RDF-triple (тройки subject-predicate-object)**. Существует проект **DBPedia**, хранящий миллиарды таких связей, собранный и самообновляющийся на материалах Википедии. **Freebase** — ещё один подобный проект. Проект **WordNet** содержит исключительно связи гипоним-гипероним. Датасет **TACRED** представляет собой 106,264 тройки 41 типа, размеченных в предложениях

**Алгоритмы выделения отношений** подразделить на 4 группы
1. Распознание на основе паттернов, заданных вручну.
2. Обучение с учителем
3. Частично контролируемое обучение
4. Обучение без учителя 

#### Распознание паттернов
Также иногда носит название "паттерны Хёрста" — по фамилии изобретателя в 1992 году. Это буквально вручную прописанные правила формата "если в приложении можно выделить паттерн $N_0$, such as $N_1$, то $N_1$ и $N_0$ связан отношением "Гипоним-гипероним". Из преимуществ этого подхода можно выделить высокую точность и возможность адаптации к довольно специфическим предметным областям. Из недостатков стоит отметить низкую полноту, высокий объём работы для ручного написания всех возможных паттернов, а также слабую работу со флективными языками.

#### Обучение с учителем
Имеется классическое машинное обучение с учителем -- с полноценным размеченным датасетом, тестовой и валидационной выборкой.
Задача может, например, быть поставлена так:
1. Выделить именованные сущности из текста
2. Подать на вход любому классификатору (на наличие отношения) все пары именованных сущностей, с учётом контекста либо без него

Классификаторы классического типа (Random Forest, линейная регрессия, перцептроны) могут принимать на вход признаки
1. **Векторное представление** — эмбеддинги BERT, tf-idf, Bag of words, "Bag of bigrams"
2.  **Признаки именованных сущностей** — тип (компания, человек, река), уровень ({NAME, NOMINAL, PRONOUN} ~ {название, тип, местоимение}, н-р, {Иван, человек, он})
3. **Синтаксические признаки** — количество других слов между именованным сущностями, синтаксические и грамматические признаки, синтаксический путь между 2 именованными сущностями

Основным недостатком такого метода является необходимость наличия размеченного датасета, что требует большого объёма усилий

#### Частично контролируемое обучение: бутстрэппинг

В отличие от обучения с учителем, этот метод не требует размеченного датасета. Для его работы достаточно нескольких **исходных паттернов (seed patterns)** или **исходных кортежей (seed tuples)**. Этого достаточно, чтобы запустить процесс **бутстрэппинга** классификатора. Например:

1. Известно, что Ryanair и Шарлеруа связаны отношением "Авиакопания-хаб".
2. Запускается поиск всех предложений, имеющих слова Ryanair, Шарлеруа, хаб.
3. Затем, из этих предложений выделяется контекст между использованными словами и, возможно, по одному слову вокруг них
4. С использованием контекста, признаков именованных сущностей и прочих черт выделяются паттерны, образующие связь "Авиакомпания-хаб"

Подобные системы могут также выдавать паттернам **меру уверенности (confidence values)**. Она используется для избежания **семантического смещения (semantic drift)** — ситуации, когда ошибочные паттерны приводят к выделению ошибочных кортежей, которые приводят к выделению ошибчоных паттернов и т д.

Уверенность в паттерне можно оценить по следующей формуле:
$$
Conf_{RlogF}(p) = \frac{|hits(p)|}{|finds(p)|}\log(|finds(p)|)
$$
где:
* **hits(p)** — количество кортежей, которые найдены данным паттерном и помечены как seed tuples на данной итерации алгоритма
* **finds(p)** — общее количество кортежей, которые найдены данным паттерном.

Уверенность в кортеже тоже можно рассчитать. Предположим, у нас есть кортеж t и набор поддерживающих его паттернов P, для каждого из которых уже тоже рассчитана мера уверенность.

Тогда уверенность в кортеже можно рассчитать с помощью техники **noisy-or** — по сути просто перемножить вероятности, что все поддерживающие паттерны ошиблись одновременно

$$
Conf(t) = 1 - \prod_{p \in P'} (1 - Conf(p))
$$

#### Частично контролируемое обучение: дистанционное обучение


Его идея заключается в том, что вместо набора из нескольких вручную заданных паттернов, мы берём данные из существующего крупного датасета и на их основе обучаем классификатор

1. Берём крупный существующий датасет (н-р, DBPedia)
2. Достаём из него все кортежи по некоторому отшению
3. Ищем все предложения, содержащих обе именованные сущности из кортежа
4. Все они признаются положительными примерами для данного типа отношений
5. На их основании можно выделить новые паттерны или же обучить классификатор, отвественный за выделение данного типа отношений. В связи с высоким объёмом обучающей выборки, можно получить довольно сложно устроенные паттерны.

Основным минусом данного подхода является высокая зашумлённость, т. к. на самом деле далеко не все найденные предложения явялются положительными примерами. То есть, метод имеет низкую точность и актуальные исследования нацелены на то, чтобы эту точность повысить. Ещё к недостаткам можно отнести потребность в большом датасете.
